{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# Appendix E: Parameter-efficient Finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1+cu124\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 Introduction to LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- No code in this section\n",
    "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
    "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- Suppose we have a large weight matrix $W$ for a given layer\n",
    "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
    "- In regular training and finetuning, the weight update is defined as follows:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
    "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
    "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
    "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- Similarly, we can write the following for LoRA:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
    "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
    "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
    "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
    "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
    "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
    "outputId": "b8c9b125-bb52-45d3-8071-fa5054dbf5a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 11.0kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.19MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 17.9kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:11<00:00, 7.00MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.74MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.80MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.61MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 Parameter-efficient finetuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
    "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
    "\n",
    "In code, this LoRA layer depicted in the figure above looks like as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
    "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
    "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
    "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
    "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
    "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
    "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
    "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
    "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
    "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
    "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
      "Ep 1 (Step 000050): Train loss 0.396, Val loss 0.364\n",
      "Ep 1 (Step 000100): Train loss 0.111, Val loss 0.229\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.135, Val loss 0.073\n",
      "Ep 2 (Step 000200): Train loss 0.011, Val loss 0.044\n",
      "Ep 2 (Step 000250): Train loss 0.026, Val loss 0.167\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.066, Val loss 0.058\n",
      "Ep 3 (Step 000350): Train loss 0.257, Val loss 0.422\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 4 (Step 000400): Train loss 0.006, Val loss 0.229\n",
      "Ep 4 (Step 000450): Train loss 0.100, Val loss 0.698\n",
      "Ep 4 (Step 000500): Train loss 0.018, Val loss 0.005\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.272, Val loss 0.051\n",
      "Ep 5 (Step 000600): Train loss 0.014, Val loss 0.024\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Training completed in 0.86 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- Finally, let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.04%\n",
      "Validation accuracy: 96.64%\n",
      "Test accuracy: 96.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22370c7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
